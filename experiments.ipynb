{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3afdcf02-dd39-4088-9a54-104a300da035",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a Jupyter notebook for re-running the experiments described in the paper titled \"Using InMap to Create Seed Mapping for Machine Learning-Based Code-to-Architecture Mappers\". This is only for double-blind review purposes, it will be made easier accessible via GitHub upon accepatence and publication of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c9d93-bf42-4f95-8dd5-c797362f1c15",
   "metadata": {},
   "source": [
    "## Manage imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b225e-d43d-4a24-883b-528c9c628b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./script')\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "import Preprocess as Prep\n",
    "import RelativePaths as RP\n",
    "import Evaluation as Eva\n",
    "import GatherData as Gather\n",
    "import Graphs as Graphs\n",
    "import Utils as Utils\n",
    "import Metrics as Metrics\n",
    "from IPython.display import display\n",
    "from itertools import chain, combinations\n",
    "import concurrent.futures\n",
    "import itertools\n",
    "import threading\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe765a82-0943-41aa-8851-e619ab6ea16d",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfe8b6-144f-4ecd-8896-0866c6de3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "inmap_result_cols = [\"pos\", \"name\", \"x\", \"y\", \"recommendation\", \"score\", \"module\", \"consistent\", \"explicit\"]\n",
    "inmap_renaming = {'ant' : {\n",
    "                            \n",
    "                            'compil' : 'compilers',\n",
    "                            'condit' : 'condition',\n",
    "                            'listen' : 'listeners',\n",
    "                            'option' : 'optional'\n",
    "                          },\n",
    "                  'argouml' : {'applicat' : 'application',\n",
    "                               'code-Generat' : 'code-generation',\n",
    "                               'configurat' : 'configuration',\n",
    "                               'explor' : 'explorer',\n",
    "                               'internationalizat' : 'internationalization',\n",
    "                               'java-Code-Generat' : 'java-code-generation',\n",
    "                               'notat' : 'notation',\n",
    "                               'persist' : 'persistence',\n",
    "                               'reverseEngineer' : 'reverse-engineering',\n",
    "                               'swing-Extens' : 'swing-extension',\n",
    "                               'task-Manage' : 'task-management'\n",
    "                              },\n",
    "                  'jabref' : {'gui ui' : 'gui'},\n",
    "                  'jittac' : {'eclipse-resource-mapp' : 'eclipse-resource-mapping',\n",
    "                              'impl-model implmodel' : 'impl-model',\n",
    "                              'resource-mapp' : 'resource-mapping'},\n",
    "                  'teammates' : {'common-data-Transf' : 'data-transfer',\n",
    "                                 'common-except' : 'exceptions',\n",
    "                                 'common-util' : 'util',\n",
    "                                 'logic-back-door' : 'logic-backdoor',\n",
    "                                 'storage-entity' : 'entity',\n",
    "                                 'storage-search' : 'search',\n",
    "                                 'ui-automate' : 'ui-automated',\n",
    "                                 'ui-controll' : 'ui-controller'}}\n",
    "INMAP_DATA_PATH = './data/inmap'\n",
    "INMAP_DATA_PATH_EXP2 = './data/inmap_exp2'\n",
    "\n",
    "systems = ['ant', 'argouml', 'jabref', 'jittac', 'teammates']\n",
    "systemNames = {'ant' : 'Ant', 'argouml' : 'ArgoUML', 'jabref' : 'JabRef', 'jittac' : 'Jittac', 'prom' : 'ProM','teammates' : 'TeamMates'}\n",
    "\n",
    "TEST_ALL_PREPROCESSING_SETTINGS = False\n",
    "STEP_PREPROCESS = True\n",
    "STEP_EVALUATE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457515c-2f37-40b5-8ddc-8381c2c85662",
   "metadata": {},
   "source": [
    "## Read configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574d189-a26b-4e26-9678-6c794289f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing settings\n",
    "path_to_yaml = './config.yaml'\n",
    "config = Utils.read_yaml_file(path_to_yaml)\n",
    "files = {}\n",
    "\n",
    "for system in systems:\n",
    "    files[system] = config['file locations'][system]\n",
    "preprocess_settings = config['preprocess settings list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e5330-ba15-4dc7-8f9d-c64cdaca2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file_locations which will be relative to computer in use\n",
    "from pathlib import Path\n",
    "raw_data_csv = {}\n",
    "system_folder = {}\n",
    "tmp_csv = {}\n",
    "table_file = {}\n",
    "for system in systems:\n",
    "    raw_data_csv[system] = str(Path.cwd() / files[system]['raw data'])\n",
    "    system_folder[system] = str(Path.cwd() / files[system]['system folder'])\n",
    "    tmp_csv[system] = str(Path.cwd() / files[system]['tmp data'])\n",
    "    table_file[system] = str(Path.cwd() / files[system]['preprocess comparisons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f4327-7c3a-4ac9-9665-6f897fe414b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20350f70-7762-40d3-b831-42858e334c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the logging\n",
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.utcnow().strftime('%Y%m%d_%H-%M-%S')\n",
    "logfilename=f'./log/experiments.log'\n",
    "#formatter = logging.Formatter('[%(asctime)s] %(name)s %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler(filename=logfilename)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(message)s',\n",
    "    handlers=[\n",
    "        file_handler\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Logfile created\")#setting up the logging\n",
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.utcnow().strftime('%Y%m%d_%H-%M-%S')\n",
    "logfilename=f'./log/experiments.log'\n",
    "#formatter = logging.Formatter('[%(asctime)s] %(name)s %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler(filename=logfilename)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(message)s',\n",
    "    handlers=[\n",
    "        file_handler\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Logfile created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf000310-f40e-493b-80ad-cac9710db48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inmap_results(data_dir, system):\n",
    "    df_total = pd.DataFrame(columns=inmap_result_cols)\n",
    "    result_files = [f for f in os.listdir(f\"{data_dir}/{system}\") if re.match(\"page-[0-9]*-recommendations-data.json\", f)]\n",
    "    for i in range(len(result_files)):\n",
    "        df = pd.read_json(f\"{data_dir}/{system}/page-{i+1}-recommendations-data.json\")\n",
    "        data_list = df['data'].values.tolist()\n",
    "        if len(data_list[0]) == 10:\n",
    "            data_list = [x[0:7] + x[8:] for x in data_list]\n",
    "        df = pd.DataFrame(data_list, columns=inmap_result_cols)\n",
    "        df_total = pd.concat([df_total,df], ignore_index=True)\n",
    "    df_total['pos'] = df_total.index + 1\n",
    "    return df_total\n",
    "\n",
    "def transform_inmap_results(df_inmap, rename_dict):\n",
    "    df_inmap['name'] = df_inmap['name'].str.split('.', n = -1, expand = False).str[-1]\n",
    "    df_inmap['name'] = df_inmap['name'].astype(str) + '.java'\n",
    "    df_inmap['consistent'] = df_inmap['consistent'].map({'true' : True, 'false' : False})\n",
    "    df_inmap['explicit'] = df_inmap['explicit'].map({'true' : True, 'false' : False})\n",
    "    df_inmap.drop(columns = ['x', 'y'], inplace=True)\n",
    "    df_inmap[['module','recommendation']].replace(to_replace=rename_dict, value=None, inplace=True)\n",
    "    df_inmap.replace({'module' : rename_dict, 'recommendation' : rename_dict}, inplace=True)\n",
    "    return df_inmap\n",
    "\n",
    "def get_correct_inmap_recommendations(df_inmap, n = 5, per_module = 0):\n",
    "    if per_module == 0:\n",
    "        return df_inmap[df_inmap['consistent'] == True].sort_values(by='pos').head(n)\n",
    "    else:\n",
    "        return df_inmap[df_inmap['consistent'] == True].sort_values(by='pos').groupby('module').head(per_module)\n",
    "\n",
    "def line_plot(title: str, x_axis, y_axis: dict, x_axis_name, y_axis_name, ax):\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_ylim(0.0, 1)\n",
    "    ax.set_ylabel(y_axis_name, fontsize=14)\n",
    "    ax.set_xlabel(x_axis_name, fontsize=14)\n",
    "\n",
    "    ax.scatter(x_axis, y_axis[\"maxEnt\"], s=40, c=\"r\", marker=\"o\", label=\"Log. Regr.\")\n",
    "    ax.plot(x_axis, y_axis[\"maxEnt\"], c=\"r\", linewidth=0.8)\n",
    "    \n",
    "    ax.scatter(x_axis, y_axis[\"naive\"], s=40, c=\"b\", marker=\"x\", label=\"Naive Bayes\")\n",
    "    ax.plot(x_axis, y_axis[\"naive\"], c=\"b\", linewidth=0.8)\n",
    "\n",
    "    ax.scatter(x_axis, y_axis[\"svm\"], s=40, c=\"y\", marker=\"^\", label=\"SVM\")\n",
    "    ax.plot(x_axis, y_axis[\"svm\"], c=\"y\", linewidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920fafb-4eec-4fdb-908a-3d7a189b14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for system in systems:\n",
    "    print(system)\n",
    "    Gather.gather_architectural_concerns_data(system_folder[system], raw_data_csv[system])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1950f0c-4b51-4981-97f9-9e00ef5ec041",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = {}\n",
    "for system in systems:\n",
    "    dataset_df[system] = pd.read_csv(raw_data_csv[system])\n",
    "    y_labels = dataset_df[system].Label.unique()\n",
    "    x_quantity = [len(dataset_df[system].loc[dataset_df[system]['Label']==label]) for label in y_labels]\n",
    "    tmp_df = pd.DataFrame({\n",
    "        'Labels' : y_labels,\n",
    "        'Quantity' : x_quantity\n",
    "    })\n",
    "    tmp_df = tmp_df.sort_values(by=['Quantity'])\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "    plt.barh(y=tmp_df.Labels, width=tmp_df.Quantity)\n",
    "    for i, v in enumerate(tmp_df.Quantity):\n",
    "        plt.text(v, i, str(v), color='black', fontweight='bold', ha='left', va='center')\n",
    "\n",
    "    plt.xlabel('Modules')\n",
    "    plt.ylabel('Number of files')\n",
    "    plt.title('Files per module for ' + systemNames[system])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e9c99-6103-49b3-a1d8-89f6e7683f97",
   "metadata": {},
   "source": [
    "## Overall InMap performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d78c44-4981-4536-b4bd-42798376a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inmap = [transform_inmap_results(load_inmap_results(INMAP_DATA_PATH, s), inmap_renaming[s]) for s in systems]\n",
    "\n",
    "data = {\n",
    "    'system' : [s for s in systems],\n",
    "    'entities' : [pd.read_csv(raw_data_csv[s]).shape[0] for s in systems],\n",
    "    'recommendations' : [df.shape[0] for df in df_inmap], \n",
    "    'correct' : [df[df['consistent']==True].shape[0] for df in df_inmap]\n",
    "                                                 \n",
    "}\n",
    "\n",
    "df_inmap_results = pd.DataFrame(data=data)\n",
    "df_inmap_results['precision'] = df_inmap_results.correct / df_inmap_results.recommendations\n",
    "df_inmap_results['recall'] = df_inmap_results.correct / df_inmap_results.entities\n",
    "\n",
    "df_inmap_results\n",
    "#for system in systems:\n",
    "#    print(f\"System {system}:\")\n",
    "#    nr_of_entities[system] = pd.read_csv(raw_data_csv[system]).shape[0]\n",
    "#    print(f\"\\tNumber of files: {nr_of_entities[system]}\")\n",
    "#    df_inmap[system] = transform_inmap_results(load_inmap_results(INMAP_DATA_PATH, system), inmap_renaming[system])\n",
    "#    print(f\"\\tNumber of recommendations: {df_inmap[system].shape[0]}\")\n",
    "#    print(f\"\\tNumber of correct recommendations {df_inmap[system][df_inmap[system]['consistent']==True].shape[0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9cae3-1874-4631-9640-5b5c9fb9827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_inmap_results.style\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249276c2-e089-44d4-8bc5-d15ca3dd59a7",
   "metadata": {},
   "source": [
    "## Relative training set sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d84af4-d19d-4bdf-951e-c62063e7e904",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb957b2-9ba6-4d7c-9c0e-fb3a25dad38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = preprocess_settings[0]\n",
    "df_sliced = {}\n",
    "processed_data_csv = {}\n",
    "for system in systems:\n",
    "    processed_data_csv[system] = str(Path.cwd() / files[system]['data size percentage'])\n",
    "    Prep.preprocess_settings(setting, raw_data_csv[system], processed_data_csv[system])\n",
    "    processed_data_df = pd.read_csv(processed_data_csv[system])\n",
    "    df_sliced[system], removed_labels = Utils.remove_concerns_under_quantity_threshold(processed_data_df, minNumOfFiles=2)\n",
    "    #df_sliced[system] = processed_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedb54a-1844-4567-a1e6-d5133a64a373",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f39e4a-1203-441a-9956-47e91f812d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sizes = [0.95, 0.9, 0.85, 0.8, 0.75]\n",
    "n_splits = 100\n",
    "maxEnt_reports = {}\n",
    "svm_reports = {}\n",
    "naive_reports = {}\n",
    "\n",
    "for system in systems:\n",
    "    print(\"Processing system \" + systemNames[system])\n",
    "    maxEnt_reports[system] = []\n",
    "    svm_reports[system] = []\n",
    "    naive_reports[system] = []\n",
    "    for test_size in test_sizes:\n",
    "        feature_representation = CountVectorizer()\n",
    "        # Train and gather evaluation metrics\n",
    "        evaluate = Eva.Evaluation(df_sliced[system], feature_representation, test_size, n_splits)\n",
    "        metrics_max_ent = evaluate.evaluate_MaxEnt()\n",
    "        metrics_svm = evaluate.evaluate_SVM()\n",
    "        metrics_naive = evaluate.evaluate_Naive_Bayes()\n",
    "        maxEnt_reports[system].append(Metrics.get_average_classification_report(metrics_max_ent))\n",
    "        svm_reports[system].append(Metrics.get_average_classification_report(metrics_svm))\n",
    "        naive_reports[system].append(Metrics.get_average_classification_report(metrics_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212dd50-01e7-47f0-bd1b-3ff6cb3bb974",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae401c-e28b-4843-bffb-40c491722cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [str(format(1 - i, '.2f')) for i in test_sizes]\n",
    "\n",
    "fig, axs = plt.subplots(len(systems), 2, figsize=(8, 10), sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    y_axis = {\n",
    "        'maxEnt': [report.loc['accuracy'][0] for report in maxEnt_reports[system]],\n",
    "        'naive': [report.loc['accuracy'][0] for report in naive_reports[system]],\n",
    "        'svm': [report.loc['accuracy'][0] for report in svm_reports[system]]\n",
    "    }\n",
    "    line_plot(\"\", x_axis, y_axis, \"W. avg. recall\" if i == len(systems) - 1 else \"\", \"\", axs[i, 1])\n",
    "\n",
    "    y_axis = {\n",
    "        'maxEnt': [report.loc['weighted avg']['precision'] for report in maxEnt_reports[system]],\n",
    "        'naive': [report.loc['weighted avg']['precision'] for report in naive_reports[system]],\n",
    "        'svm': [report.loc['weighted avg']['precision'] for report in svm_reports[system]]\n",
    "    }\n",
    "    line_plot(\"\", x_axis, y_axis, \"W. avg. prec\" if i == len(systems) - 1 else \"\", systemNames[system], axs[i, 0])\n",
    "\n",
    "#    y_axis = {\n",
    "#        'maxEnt': [report.loc['macro avg']['precision'] for report in maxEnt_reports[system]],\n",
    "#        'naive': [report.loc['macro avg']['precision'] for report in naive_reports[system]],\n",
    "#        'svm': [report.loc['macro avg']['precision'] for report in svm_reports[system]]\n",
    "#    }\n",
    "#    line_plot(\"\", x_axis, y_axis, \"Avg. prec.\" if i == len(systems) - 1 else \"\", \"\", axs[i, 2])\n",
    "\n",
    "#    y_axis = {\n",
    "#        'maxEnt': [report.loc['macro avg']['recall'] for report in maxEnt_reports[system]],\n",
    "#        'naive': [report.loc['macro avg']['recall'] for report in naive_reports[system]],\n",
    "#        'svm': [report.loc['macro avg']['recall'] for report in svm_reports[system]]\n",
    "#    }\n",
    "#    line_plot(\"\", x_axis, y_axis, \"Avg. recall\" if i == len(systems) - 1 else \"\", \"\", axs[i, 3])\n",
    "for ax in [a for b in axs for a in b]:\n",
    "    ax.label_outer()\n",
    "handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, bbox_to_anchor=(0.5, -0.05, 0, 0), loc='lower center', ncol=3, fontsize=14, markerscale=1.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc7e25-f010-4eb8-b8a0-e8365f6c5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_table = pd.DataFrame()\n",
    "for system in systems:\n",
    "    for i, seed in enumerate(test_sizes):\n",
    "        df_tmp = maxEnt_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'maxent'\n",
    "        df_tmp['seed'] = 1 - seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = naive_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'naive'\n",
    "        df_tmp['seed'] = 1 - seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "        \n",
    "        df_tmp = svm_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'svm'\n",
    "        df_tmp['seed'] = 1 - seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "\n",
    "df_summary_table.pivot_table(index=['system','classifier'], columns=['seed'], values=['precision', 'recall']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d618c-9359-4822-80ba-97f56f1ac451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_summary_table.pivot_table(index=['system','classifier'], columns=['seed'], values=['precision', 'recall'])\n",
    "s = df_pivot.style\n",
    "s.format('{:.2f}')\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d498fe5-41fa-4ff9-a74b-53e4fc4eebbe",
   "metadata": {},
   "source": [
    "## Initial Mapping with InMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604f100-892f-4aaa-a322-8418f01fc456",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68690fb-c9ca-4de3-a0dc-a7889cdb911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = preprocess_settings[0]\n",
    "df_sliced = {}\n",
    "processed_data_csv = {}\n",
    "processed_data_df = {}\n",
    "\n",
    "for system in systems:\n",
    "    processed_data_csv[system] = str(Path.cwd() / files[system]['data inmap relative seed'])\n",
    "    Prep.preprocess_settings(setting, raw_data_csv[system], processed_data_csv[system])\n",
    "    processed_data_df[system] = pd.read_csv(processed_data_csv[system])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e21f68d-90a4-4288-871a-888d5e984838",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df29512-572b-407d-b52b-e20b30cc8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_sizes = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "maxEnt_reports = {}\n",
    "svm_reports = {}\n",
    "naive_reports = {}\n",
    "\n",
    "for system in systems:\n",
    "    print(f\"Processing {systemNames[system]}...\")\n",
    "    maxEnt_reports[system] = []\n",
    "    svm_reports[system] = []\n",
    "    naive_reports[system] = []  \n",
    "    \n",
    "    df_inmap = transform_inmap_results(load_inmap_results(INMAP_DATA_PATH, system), inmap_renaming[system])\n",
    "    \n",
    "    for seed_size in seed_sizes:\n",
    "        df_inmap_seed = get_correct_inmap_recommendations(df_inmap, n = math.ceil(seed_size * processed_data_df[system].shape[0]))\n",
    "        \n",
    "        feature_representation = CountVectorizer()\n",
    "        # Train and gather evaluation metrics\n",
    "        #df_sliced, removed_labels = Utils.remove_concerns_under_quantity_threshold(processed_data_df[system])\n",
    "        df_sliced = processed_data_df[system]\n",
    "        evaluate = Eva.Evaluation(dataFrame = df_sliced, feature_vector = feature_representation, df_training = df_inmap_seed)\n",
    "        metrics_max_ent = evaluate.evaluate_MaxEnt(type = 'split')\n",
    "        metrics_svm = evaluate.evaluate_SVM(type = 'split')\n",
    "        metrics_naive = evaluate.evaluate_Naive_Bayes(type = 'split')\n",
    "        maxEnt_reports[system].append(Metrics.get_average_classification_report(metrics_max_ent))\n",
    "        svm_reports[system].append(Metrics.get_average_classification_report(metrics_svm))\n",
    "        naive_reports[system].append(Metrics.get_average_classification_report(metrics_naive))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62e5b4-0454-4ac7-a4cf-367b2e4047bb",
   "metadata": {},
   "source": [
    "## Effort for Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc658d-fddb-4d55-abd9-af13fc4ffdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['system', 'rel_seed', 'recommendations', 'mappings', 'precision']\n",
    "df_inmap_effort = pd.DataFrame(columns=columns)\n",
    "for system in systems:\n",
    "    for seed_size in seed_sizes:\n",
    "        df_entry = pd.DataFrame(columns=columns)\n",
    "        df_inmap_seed = get_correct_inmap_recommendations(df_inmap, n = math.ceil(seed_size * processed_data_df[system].shape[0]))\n",
    "        df_entry['system']  = [system]\n",
    "        df_entry['rel_seed'] = seed_size\n",
    "        df_entry['recommendations'] = df_inmap_seed['pos'].max() + 1\n",
    "        df_entry['mappings'] = df_inmap_seed.shape[0]\n",
    "        df_inmap_effort = pd.concat([df_inmap_effort, df_entry], ignore_index=True)\n",
    "df_inmap_effort['precision'] = df_inmap_effort['mappings'] / df_inmap_effort['recommendations']\n",
    "df_inmap_effort.pivot_table(index='system', columns='rel_seed', values='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36ec2a-7ab4-413e-ac57-3f67c6ca6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_inmap_effort.pivot_table(index='system', columns='rel_seed', values='precision').style\n",
    "s.format('{:.2f}')\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc904d-7d51-453a-a8c1-739b4d11f0e3",
   "metadata": {},
   "source": [
    "### Visualization: Label distribution in Seed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e0c7d-84c5-478a-bc04-d2bba10a106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(systems), len(seed_sizes), figsize = (30, 25), squeeze=False)\n",
    "for i, system in enumerate(systems):\n",
    "    df_inmap = transform_inmap_results(load_inmap_results(INMAP_DATA_PATH, system), inmap_renaming[system])\n",
    "    for j, seed_size in enumerate(seed_sizes):\n",
    "        df_inmap_seed = get_correct_inmap_recommendations(df_inmap, n = math.ceil(seed_size * processed_data_df[system].shape[0]))\n",
    "        sns.countplot(data = df_inmap_seed, y = 'module', orient = 'h', ax = axs[i, j])\n",
    "        axs[i, j].set_xlabel(f\"Seed mapping size at {seed_size} of the overall system ({df_inmap_seed['pos'].iat[-1]}).\")\n",
    "        axs[i, j].set_ylabel(systemNames[system] if j == 0 else \"\")\n",
    "        axs[i, j].bar_label(axs[i, j].containers[0])\n",
    "fig.savefig('./seed_dist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2742a0-1098-414f-af3a-4286c144b28e",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6abac6-aa46-4382-ac5a-dc27b85926cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [str(format(i, '.2f')) for i in seed_sizes]\n",
    "\n",
    "fig, axs = plt.subplots(len(systems), 2, figsize=(8, 10), sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    y_axis = {\n",
    "        'maxEnt': [report.loc['accuracy'][0] for report in maxEnt_reports[system]],\n",
    "        'naive': [report.loc['accuracy'][0] for report in naive_reports[system]],\n",
    "        'svm': [report.loc['accuracy'][0] for report in svm_reports[system]]\n",
    "    }\n",
    "    line_plot(\"\", x_axis, y_axis, \"W. avg. recall\" if i == len(systems) - 1 else \"\", \"\", axs[i, 1])\n",
    "\n",
    "    y_axis = {\n",
    "        'maxEnt': [report.loc['weighted avg']['precision'] for report in maxEnt_reports[system]],\n",
    "        'naive': [report.loc['weighted avg']['precision'] for report in naive_reports[system]],\n",
    "        'svm': [report.loc['weighted avg']['precision'] for report in svm_reports[system]]\n",
    "    }\n",
    "    line_plot(\"\", x_axis, y_axis, \"W. avg. prec\" if i == len(systems) - 1 else \"\", systemNames[system], axs[i, 0])\n",
    "\n",
    "#    y_axis = {\n",
    "#        'maxEnt': [report.loc['macro avg']['precision'] for report in maxEnt_reports[system]],\n",
    "#        'naive': [report.loc['macro avg']['precision'] for report in naive_reports[system]],\n",
    "#        'svm': [report.loc['macro avg']['precision'] for report in svm_reports[system]]\n",
    "#    }\n",
    "#    line_plot(\"\", x_axis, y_axis, \"Avg. prec.\" if i == len(systems) - 1 else \"\", \"\", axs[i, 2])\n",
    "\n",
    "#    y_axis = {\n",
    "#        'maxEnt': [report.loc['macro avg']['recall'] for report in maxEnt_reports[system]],\n",
    "#        'naive': [report.loc['macro avg']['recall'] for report in naive_reports[system]],\n",
    "#        'svm': [report.loc['macro avg']['recall'] for report in svm_reports[system]]\n",
    "#    }\n",
    "#    line_plot(\"\", x_axis, y_axis, \"Avg. recall\" if i == len(systems) - 1 else \"\", \"\", axs[i, 3])\n",
    "for ax in [a for b in axs for a in b]:\n",
    "    ax.label_outer()\n",
    "handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, bbox_to_anchor=(0.5, -0.05, 0, 0), loc='lower center', ncol=3, fontsize=14, markerscale=1.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5614584-73e9-4705-810d-1bfb7bea3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_table = pd.DataFrame()\n",
    "for system in systems:\n",
    "    for i, seed in enumerate(seed_sizes):\n",
    "        df_tmp = maxEnt_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'maxent'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = naive_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'naive'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "        \n",
    "        df_tmp = svm_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'svm'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "\n",
    "df_summary_table.pivot_table(index=['system','classifier'], columns=['seed'], values=['precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6167bd-6c28-455c-be65-2ab0a05174db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_summary_table.pivot_table(index=['system','classifier'], columns=['seed'], values=['precision', 'recall'])\n",
    "s = df_pivot.style\n",
    "s.format('{:.2f}')\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d38eb-b2b9-43c8-96c7-33b204f2b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_report = {}\n",
    "for system in systems:\n",
    "    merged_report[system] = pd.DataFrame()\n",
    "    for i, seed in enumerate(seed_sizes):\n",
    "        df_tmp = maxEnt_reports[system][i].drop(index=['accuracy', 'macro avg', 'weighted avg']).reset_index()\n",
    "        df_tmp['classifier'] = 'maxent'\n",
    "        df_tmp['seed_size'] = seed\n",
    "        merged_report[system] = pd.concat([merged_report[system], df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = naive_reports[system][i].drop(index=['accuracy', 'macro avg', 'weighted avg']).reset_index()\n",
    "        df_tmp['classifier'] = 'naive'\n",
    "        df_tmp['seed_size'] = seed\n",
    "        merged_report[system] = pd.concat([merged_report[system], df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = svm_reports[system][i].drop(index=['accuracy', 'macro avg', 'weighted avg']).reset_index()\n",
    "        df_tmp['classifier'] = 'svm'\n",
    "        df_tmp['seed_size'] = seed\n",
    "        merged_report[system] = pd.concat([merged_report[system], df_tmp], ignore_index=True)\n",
    "    merged_report[system].rename(columns={'index' : 'module'}, inplace = True)\n",
    "    merged_report_p = merged_report[system].drop(columns = ['recall', 'f1-score'])\n",
    "    merged_report_r = merged_report[system].drop(columns = ['precision', 'f1-score'])\n",
    "    merged_report_p['metric'] = 'precision'\n",
    "    merged_report_p.rename(columns={'precision':'value'}, inplace=True)\n",
    "    merged_report_r['metric'] = 'recall'\n",
    "    merged_report_r.rename(columns={'recall':'value'}, inplace=True)\n",
    "    merged_report[system] = pd.concat([merged_report_p, merged_report_r], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d8760-fc73-4812-adc2-f18963a87642",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(systems), len(seed_sizes), figsize = (35,25), squeeze=False)\n",
    "for i, system in enumerate(systems):\n",
    "    df_inmap = transform_inmap_results(load_inmap_results(INMAP_DATA_PATH, system), inmap_renaming[system])\n",
    "    for j, seed_size in enumerate(seed_sizes):\n",
    "        df_prec = merged_report[system][(merged_report[system]['classifier'] == 'svm') &\n",
    "                                        (np.isclose(merged_report[system]['seed_size'], seed_size))] \n",
    "        df_inmap_seed = get_correct_inmap_recommendations(df_inmap, n = math.ceil(seed_size * processed_data_df[system].shape[0]))\n",
    "        df_prec = df_prec[df_prec['module'].isin(df_inmap_seed.module)]\n",
    "        ax2 = axs[i, j].twiny()\n",
    "        ax2.grid(False)\n",
    "        sns.scatterplot(data=df_prec.sort_values('module'), x='value', style='metric', y='module',  ax = ax2) \n",
    "        sns.countplot(data = df_inmap_seed.sort_values('module'), y = 'module', orient = 'h', ax = axs[i,j], saturation=0.5, palette='light:#5A9')\n",
    "        axs[i,j].set_ylabel(systemNames[system] if j == 0 else \"\")\n",
    "        axs[i,j].set_xlabel(f\"Mappings for seed size {seed_sizes[j]}\" if i == len(systems) - 1 else \"\")\n",
    "        ax2.set_xlabel(\"Precision/recall per module\" if i == 0 else \"\")\n",
    "        ax2.get_legend().remove()\n",
    "        axs[i,j].bar_label(axs[i,j].containers[0])\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, bbox_to_anchor=(0.5, 0.0, 0, 0), loc='lower center', ncol=2, fontsize=14, markerscale=1.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4f203-af13-4f90-9b1c-5eed7e38d9b9",
   "metadata": {},
   "source": [
    "## Initial Mapping with InMap and Minimal Number of Mapping per Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd296d-8afe-45d4-88a5-970436ffa2ea",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d8da2-6d53-44fd-8eb1-eaaf91bb4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = preprocess_settings[0]\n",
    "df_sliced = {}\n",
    "processed_data_csv = {}\n",
    "processed_data_df = {}\n",
    "\n",
    "for system in systems:\n",
    "    processed_data_csv[system] = str(Path.cwd() / files[system]['data inmap module seed'])\n",
    "    Prep.preprocess_settings(setting, raw_data_csv[system], processed_data_csv[system])\n",
    "    processed_data_df[system] = pd.read_csv(processed_data_csv[system])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb0386-0e36-4f4d-9583-221d344d83f0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f84a8-eded-4032-8432-777957799199",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_sizes = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "pm = {}\n",
    "maxEnt_reports = {}\n",
    "svm_reports = {}\n",
    "naive_reports = {}\n",
    "\n",
    "for system in systems:\n",
    "    maxEnt_reports[system] = []\n",
    "    svm_reports[system] = []\n",
    "    naive_reports[system] = []  \n",
    "    pm[system] = [math.ceil(seed_size * processed_data_df[system].shape[0] / processed_data_df[system].Label.nunique()) for seed_size in seed_sizes]\n",
    "    \n",
    "    df_inmap = transform_inmap_results(load_inmap_results(INMAP_DATA_PATH_EXP2, system), inmap_renaming[system])\n",
    "    \n",
    "    for i, seed_size in enumerate(seed_sizes):\n",
    "        df_inmap_seed = get_correct_inmap_recommendations(df_inmap, per_module=pm[system][i])\n",
    "         \n",
    "        feature_representation = CountVectorizer()\n",
    "        # Train and gather evaluation metrics\n",
    "        #df_sliced, removed_labels = Utils.remove_concerns_under_quantity_threshold(processed_data_df[system])\n",
    "        df_sliced = processed_data_df[system]\n",
    "        evaluate = Eva.Evaluation(dataFrame = df_sliced, feature_vector = feature_representation, df_training = df_inmap_seed)\n",
    "        metrics_max_ent = evaluate.evaluate_MaxEnt(type = 'split')\n",
    "        metrics_svm = evaluate.evaluate_SVM(type = 'split')\n",
    "        metrics_naive = evaluate.evaluate_Naive_Bayes(type = 'split')\n",
    "        maxEnt_reports[system].append(Metrics.get_average_classification_report(metrics_max_ent))\n",
    "        svm_reports[system].append(Metrics.get_average_classification_report(metrics_svm))\n",
    "        naive_reports[system].append(Metrics.get_average_classification_report(metrics_naive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b613e3-80f6-4261-8a1c-ec91728273e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['system', 'rel_seed', 'recommendations', 'mappings', 'precision']\n",
    "df_inmap_effort = pd.DataFrame(columns=columns)\n",
    "for system in systems:\n",
    "    pm[system] = [math.ceil(seed_size * processed_data_df[system].shape[0] / processed_data_df[system].Label.nunique()) for seed_size in seed_sizes]\n",
    "    df_inmap = transform_inmap_results(load_inmap_results(INMAP_DATA_PATH_EXP2, system), inmap_renaming[system])\n",
    "    \n",
    "    for i, seed_size in enumerate(seed_sizes):\n",
    "        df_entry = pd.DataFrame(columns=columns)\n",
    "        nr_of_rec = 0\n",
    "        df_inmap_seed = get_correct_inmap_recommendations(df_inmap, per_module=pm[system][i])\n",
    "        for m in df_inmap_seed['module'].unique():\n",
    "            #get max position for module in seed -> the we are done finding mapping for the seed\n",
    "            max_pos = df_inmap_seed[df_inmap_seed['recommendation'] == m]['pos'].max()\n",
    "            #get all recommendation from df_inmap recommending module smaller than pos\n",
    "            nr_of_rec += df_inmap[(df_inmap['recommendation'] == m) & (df_inmap['pos'] <= max_pos)].shape[0]\n",
    "        df_entry['system']  = [system]\n",
    "        df_entry['rel_seed'] = seed_size\n",
    "        df_entry['recommendations'] = nr_of_rec\n",
    "        df_entry['mappings'] = df_inmap_seed.shape[0]\n",
    "        df_inmap_effort = pd.concat([df_inmap_effort, df_entry], ignore_index=True)\n",
    "df_inmap_effort['precision'] = df_inmap_effort['mappings'] / df_inmap_effort['recommendations']\n",
    "df_pivot = df_inmap_effort.pivot_table(index='system', columns='rel_seed', values='precision')\n",
    "s = df_pivot.style\n",
    "s.format('{:.2f}')\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb1df1d-c97d-4b4d-9a49-7de4b937d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_table = pd.DataFrame()\n",
    "for system in systems:\n",
    "    for i, seed in enumerate(seed_sizes):\n",
    "        df_tmp = maxEnt_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'maxent'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = naive_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'naive'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "        \n",
    "        df_tmp = svm_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'svm'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "\n",
    "df_summary_table.pivot_table(index=['system','classifier'], columns=['seed'], values=['precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd99678-2112-4164-af0d-7e8435c01a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_summary_table.pivot_table(index=['system','classifier'], columns=['seed'], values=['precision', 'recall'])\n",
    "s = df_pivot.style\n",
    "s.format('{:.2f}')\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504a19a-7008-435d-bc0f-7c4729cc96dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baa9f893-1ca2-4134-a7b4-e2cee8798024",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723e1ad-92bf-4a45-97a7-3aa27016531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(systems), 2, figsize=(8, 10), sharex=False, sharey=False, squeeze=False)\n",
    "\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    x_axis = [str(format(i, '.0f')) for i in pm[system]]\n",
    "    y_axis = {\n",
    "        'maxEnt': [report.loc['weighted avg']['recall'] for report in maxEnt_reports[system]],\n",
    "        'naive': [report.loc['weighted avg']['recall'] for report in naive_reports[system]],\n",
    "        'svm': [report.loc['weighted avg']['recall'] for report in svm_reports[system]]\n",
    "    }\n",
    "    line_plot(\"\", x_axis, y_axis, \"W. avg. recall\" if i == len(systems) - 1 else \"\", \"\", axs[i, 1])\n",
    "\n",
    "    y_axis = {\n",
    "        'maxEnt': [report.loc['weighted avg']['precision'] for report in maxEnt_reports[system]],\n",
    "        'naive': [report.loc['weighted avg']['precision'] for report in naive_reports[system]],\n",
    "        'svm': [report.loc['weighted avg']['precision'] for report in svm_reports[system]]\n",
    "    }\n",
    "    line_plot(\"\", x_axis, y_axis, \"W. avg. prec\" if i == len(systems) - 1 else \"\", systemNames[system], axs[i, 0])\n",
    "\n",
    "handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, bbox_to_anchor=(0.5, -0.05, 0, 0), loc='lower center', ncol=3, fontsize=14, markerscale=1.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e99b4e-c007-460c-ad5f-25888c1b6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_table = pd.DataFrame()\n",
    "for system in systems:\n",
    "    for i, seed in enumerate(seed_sizes):\n",
    "        df_tmp = maxEnt_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'maxent'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = naive_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'naive'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "        \n",
    "        df_tmp = svm_reports[system][i].loc[['weighted avg'], ['precision', 'recall']]\n",
    "        df_tmp['classifier'] = 'svm'\n",
    "        df_tmp['seed'] = seed\n",
    "        df_tmp['system'] = system\n",
    "        df_summary_table = pd.concat([df_summary_table, df_tmp], ignore_index=True)\n",
    "\n",
    "\n",
    "df_summary_table.pivot_table(index=['system','classifier'], columns=['seed'], values=['precision', 'recall']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af5083-9611-43cb-943b-b08e495f951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_report = {}\n",
    "for system in systems:\n",
    "    merged_report[system] = pd.DataFrame()\n",
    "    for i, seed in enumerate(pm[system]):\n",
    "        df_tmp = maxEnt_reports[system][i].drop(index=['accuracy', 'macro avg', 'weighted avg', 'micro avg'], errors='ignore').reset_index()\n",
    "        df_tmp['classifier'] = 'maxent'\n",
    "        df_tmp['seed_size'] = seed\n",
    "        merged_report[system] = pd.concat([merged_report[system], df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = naive_reports[system][i].drop(index=['accuracy', 'macro avg', 'weighted avg', 'micro avg'], errors='ignore').reset_index()\n",
    "        df_tmp['classifier'] = 'naive'\n",
    "        df_tmp['seed_size'] = seed\n",
    "        merged_report[system] = pd.concat([merged_report[system], df_tmp], ignore_index=True)\n",
    "\n",
    "        df_tmp = svm_reports[system][i].drop(index=['accuracy', 'macro avg', 'weighted avg', 'micro avg'], errors='ignore').reset_index()\n",
    "        df_tmp['classifier'] = 'svm'\n",
    "        df_tmp['seed_size'] = seed\n",
    "        merged_report[system] = pd.concat([merged_report[system], df_tmp], ignore_index=True)\n",
    "    merged_report[system].rename(columns={'index' : 'module'}, inplace = True)\n",
    "    merged_report_p = merged_report[system].drop(columns = ['recall', 'f1-score'])\n",
    "    merged_report_r = merged_report[system].drop(columns = ['precision', 'f1-score'])\n",
    "    merged_report_p['metric'] = 'precision'\n",
    "    merged_report_p.rename(columns={'precision':'value'}, inplace=True)\n",
    "    merged_report_r['metric'] = 'recall'\n",
    "    merged_report_r.rename(columns={'recall':'value'}, inplace=True)\n",
    "    merged_report[system] = pd.concat([merged_report_p, merged_report_r], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215eeefe-1eb6-4a46-8e97-dc8e4e98ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(systems), len(seed_sizes), figsize = (35,25), squeeze=False)\n",
    "for i, system in enumerate(systems):\n",
    "    df_inmap = transform_inmap_results(load_inmap_results(INMAP_DATA_PATH_EXP2, system), inmap_renaming[system])\n",
    "    for j, seed_size in enumerate(pm[system]):\n",
    "        df_prec = merged_report[system][(merged_report[system]['classifier'] == 'svm') &\n",
    "                                        (np.isclose(merged_report[system]['seed_size'], seed_size))] \n",
    "        df_inmap_seed = get_correct_inmap_recommendations(df_inmap, per_module=seed_size)\n",
    "        df_prec = df_prec[df_prec['module'].isin(df_inmap_seed.module)]\n",
    "        ax2 = axs[i, j].twiny()\n",
    "        ax2.grid(False)\n",
    "\n",
    "        sns.scatterplot(data=df_prec.sort_values('module'), x='value', style='metric', y='module',  ax = ax2) \n",
    "        sns.countplot(data = df_inmap_seed.sort_values('module'), y = 'module', orient = 'h', ax = axs[i,j], saturation=0.5, palette='light:#5A9')\n",
    "        axs[i,j].set_ylabel(systemNames[system] if j == 0 else \"\")\n",
    "        axs[i,j].set_xlabel(f\"Mappings for seed size {seed_sizes[j]}\" if i == len(systems) - 1 else \"\")\n",
    "        ax2.set_xlabel(\"Precision/recall per module\" if i == 0 else \"\")\n",
    "        ax2.get_legend().remove()\n",
    "        axs[i,j].bar_label(axs[i,j].containers[0])\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, bbox_to_anchor=(0.5, -0.1, 0, 0), loc='lower center', ncol=2, fontsize=14, markerscale=1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
